{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vjZBDLTYnx3o",
        "5Yp88jLH828q"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **(1) SETUP**"
      ],
      "metadata": {
        "id": "3PdcBWtC7XeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the Library**"
      ],
      "metadata": {
        "id": "JLgnXEZfp-5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the pandas library \n",
        "import pandas as pd \n",
        "# importing matplotlib library\n",
        "import matplotlib.pyplot as plt \n",
        "# importing numpy library\n",
        "import numpy as np \n",
        "# importing seaborn library\n",
        "import seaborn as sns \n",
        "# importing preprocessing module from sklearn library\n",
        "from sklearn import preprocessing \n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "NXEX3se2qCx-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **(2) Import Test Dataset**\n",
        "\n",
        "| Enter file name and path in read.csv() to load test data\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "EMJv2dIhqIOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the dataset from csv format and storing it in dataframe named 'df'\n",
        "df = pd.read_csv('.csv') "
      ],
      "metadata": {
        "id": "b8kgQnzmqKMd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(3) Separating numerical and categorical data from the input features**"
      ],
      "metadata": {
        "id": "i_Pe-oy84gR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Numerical data from the dataset\n",
        "numerical_data = df.select_dtypes(include=[np.number]) \n",
        "# Extracting Categorical data from the dataset\n",
        "categorical_data = df.select_dtypes(exclude=[np.number]) "
      ],
      "metadata": {
        "id": "-1mpAz5a4f_r"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(4) DATA PRE-PROCESSING**"
      ],
      "metadata": {
        "id": "vjZBDLTYnx3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Converting categorical data to numeric data using encoding**\n",
        "---"
      ],
      "metadata": {
        "id": "5Yp88jLH828q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Label Encoding**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ii-tLXv-8XNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR ORDINAL CATEGORICAL VARIABLES**\n",
        "\n",
        "\n",
        "> For our dataset, we have only 1 ordinal categorical variable i.e 'education' - having categories : primary, secondary, tertiary which is converted to 0,1 and 2 respectively\n",
        "\n"
      ],
      "metadata": {
        "id": "MM443-f112yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating an object label_encoder of class 'LabelEncoder' to use it for applying label encoding\n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "print(categorical_data.head())\n",
        "# Applying Label Encoding to 'education' column\n",
        "temp = label_encoder.fit_transform(categorical_data['education'])\n",
        "print('\\n')\n",
        "# Replacing the original values with the encoded values\n",
        "categorical_data['education']= temp\n",
        "# View the dataset\n",
        "print(categorical_data.head())"
      ],
      "metadata": {
        "id": "SzpLPMxB8WhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR BINARY CATEGORICAL VARIABLES**\n",
        "\n",
        "\n",
        "\n",
        "> For 'default', 'housing' and 'loan' features, we convert yes to 1 and no to 0\n",
        "\n"
      ],
      "metadata": {
        "id": "1dro2tQb1qsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an object label_encoder of class 'LabelEncoder' to use it for applying label encoding\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# View data before conversion\n",
        "print(categorical_data.head())\n",
        "\n",
        "# identifying number of unique values in each categorical variable. So that binary categorical variables can be used to convert to 0,1 using label encoding\n",
        "for i in categorical_data:\n",
        "  print(i,': ',categorical_data[i].nunique())\n",
        "  # check for binary categorical variables i.e features having just 2 classes\n",
        "  if categorical_data[i].nunique()==2:\n",
        "    # Applying Label Encoding and store it in new column\n",
        "    categorical_data.loc[:,i+' (Label Encoding)']= label_encoder.fit_transform(categorical_data[i])\n",
        "    # copy the values from new column to old column in order to replace the original categorical values by numerical values\n",
        "    categorical_data.loc[:,i] = categorical_data.loc[:,i+' (Label Encoding)']\n",
        "    # delete the newly created columns once the values are copied\n",
        "    del categorical_data[i+' (Label Encoding)']\n",
        "\n",
        "# View data after conversion\n",
        "print(categorical_data.head())"
      ],
      "metadata": {
        "id": "EmjHru511oZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ONE-HOT/DUMMY ENCODING FOR NOMINAL CATEGORICAL VARIABLES**\n",
        "\n",
        "For 'job', 'marital', 'contact' and 'poutcome' variables, we apply one-hot encoding technique\n",
        "\n"
      ],
      "metadata": {
        "id": "i1XtIkvI8pHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View data before conversion\n",
        "print(categorical_data.head())\n",
        "for i in categorical_data:\n",
        "  print(i,': ',categorical_data[i].nunique())\n",
        "  # check for multiple categorical variables i.e features having more than 2 classes but excluding 'education' where we have already applied label encoding \n",
        "  if categorical_data[i].nunique()!=2 and i!='education':\n",
        "    # Applying One Hot Encoding\n",
        "    dummies = pd.get_dummies(categorical_data[i]) \n",
        "    # renaming columns to avoid duplicate names like 'unknown' which exists in each of poutcome, education, contact, etc\n",
        "    dummies = dummies.add_prefix(i+': ')  \n",
        "    # Avoiding the dummy trap by removing the last extra column generated\n",
        "    dummies.drop(columns=dummies.columns[-1], axis=1,  inplace=True)\n",
        "    # Adding the newly generated columns to the original dataset\n",
        "    categorical_data = pd.concat([categorical_data,dummies],axis=1)\n",
        "    # Delete the original categorical column \n",
        "    del categorical_data[i]\n",
        "\n",
        "# View data after conversion\n",
        "print(categorical_data.head())"
      ],
      "metadata": {
        "id": "4Lt39xBO8sCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Standardization of numerical data**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2vzpM-1CiCK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardizing all numerical values \n",
        "# importing the StandardScaler module from sklearn.preprocessing package\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Creating an object of StandardScaler()\n",
        "object= StandardScaler()\n",
        " \n",
        "# Applying fit_transform() to standardize the numerical data and save it in 'scale'\n",
        "scale = object.fit_transform(numerical_data) \n",
        "\n",
        "# Standardized data is stored in dataframe with appropriate column names\n",
        "scaled_numerical_data = pd.DataFrame(scale, columns = numerical_data.columns)\n",
        "\n",
        "# Printing the standardized values\n",
        "print(scaled_numerical_data)"
      ],
      "metadata": {
        "id": "lQgnREqkiBck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Combining Processed Dataset and implementing Feature Selection to use with ML model**"
      ],
      "metadata": {
        "id": "CcLJtIKlAw4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining processed categorical data and numerical data to get the final processed dataset\n",
        "processed_x = pd.concat([scaled_numerical_data,categorical_data],axis=1)\n",
        "processed_x.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Dropping 50% of the features having low feature importance values\n",
        "\n",
        "processed_x.drop(['job: student', 'poutcome: failure', 'job: unemployed', 'job: entrepreneur', 'default', 'poutcome: other', 'job: self-employed', 'job: housemaid'],axis = 1, inplace=True)\n",
        "# Dropping \"duration\" feature as it will not be used for training the model\n",
        "processed_x.drop([\"duration\"],axis = 1, inplace=True)\n",
        "# Checking the shape of the final input features features which will be used for training the ML models\n",
        "print(processed_x.shape)\n"
      ],
      "metadata": {
        "id": "ZwTXKprUAwfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0cd38a-e20f-4591-f520-40f124556b09"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4000, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(5) MODEL PREDICTION**"
      ],
      "metadata": {
        "id": "mFr17wFgiTl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing pickle package to load ML model\n",
        "import pickle\n",
        "# Loading the trained model by reading the binary file\n",
        "loaded_model = pickle.load(open('Model_final.pkl','rb'))\n",
        "\n",
        "# Rearranging the columns in the format required for the model (i.e in the format how the model was trained using training dataset)\n",
        "processed_x = processed_x[['age', 'balance', 'day', 'campaign', 'pdays', 'previous', 'education','housing', 'loan', 'job: admin.', 'job: blue-collar', 'job: management','job: retired', 'job: services', 'job: technician', 'marital: divorced','marital: married', 'contact: cellular', 'contact: telephone','poutcome: success']]\n",
        "# Predicting output\n",
        "test = loaded_model.predict(processed_x)\n",
        "# Converting the output values into dataframe and giving it column name 'y'\n",
        "y = pd.DataFrame(test,columns=['y'])\n",
        "\n",
        "# Converting the output into categorical format i.e 1->'yes' and 0->'no'\n",
        "y['y'] = y['y'].map({1:'yes', 0:'no'})\n",
        "# Merging input features and predicted output into single dataframe\n",
        "final_dataset = pd.concat([df,y],axis=1)\n",
        "\n",
        "# View the predicted values in the dataset\n",
        "print(final_dataset.head())\n"
      ],
      "metadata": {
        "id": "weZeNStfibi2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}